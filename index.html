<!doctype html>
<html lang="en">

<head>
    <title>Web Scraper</title>
    <h1> Web Scraper </h1>
    <script src="https://cdn.jsdelivr.net/pyodide/v0.22.1/full/pyodide.js"></script>
    <link rel="stylesheet" href="/styles.css">
    <link rel="stylesheet" href="https://pyscript.net/latest/pyscript.css" />
    <script defer src="https://pyscript.net/latest/pyscript.js"></script>
    <script>await pyodide.loadPackage('beautifulsoup4')</script>


    <nav>
        <ul>
            <li><a href="/index.html">Main</a></li>
            <li><a href="/how-to.html">How-To</a></li>
        </ul>
    </nav>

</head>

<body>

    <div id="mainForm">
        <form action="/scraped_data.html">
            <label for="websiteInput">What website do you want to scrape?</label>
            <br>
            <textarea id="websiteInput" name="websiteInput" rows="10" cols="70">
                </textarea><br><br>
            <label for="keywords">Keywords</label>
            <br>
            <input type="text" id="keywords" name="keywords"><br><br>
        </form>

        <script type="text/javascript">
            async function loadPythonCode() {
                const response = await fetch('webscraper.py');
                const pythonCode = await response.text();
                return pythonCode;
              }
        </script>

        <py-script src="./webscraper.py"></py-script>


        <button type="submit" id="scrapeButton" onClick=>Scrape!</button>

    </div>


    <!--
        <py-config>
        [[fetch]]
        files = ["./webscraper.py"]
        </py-config>
        <py-script>
            from webscraper import lets_go_scraping
            print(lets_go_scraping())
        </py-script>
    -->
    <!--
            <script>
                <pyscript>
                import requests
                import csv
                from bs4 import BeautifulSoup
                from pyscript import *

                def lets_go_scraping():
                    #Obtain URL and keywords
                    url = input("Enter the URL you want to scrape: ")
                    keywords = input("Enter the keywords you want to search for, separated by commas: ").split(",")

                    # Send a GET request to the URL and parse the response with Beautiful Soup
                    try:
                        response = requests.get(url)
                        soup = BeautifulSoup(response.text, 'html.parser')
                    except:
                        print("Error parsing information")

                    # Find all the paragraphs in the HTML and search for the keywords in them

                    for paragraph in soup.find_all('p'):
                        for keyword in keywords:
                            try:
                                if keyword.strip().lower() in paragraph.get_text().strip().lower():
                                results = paragraph.get_text().strip()
                                print(f"Keyword '{keyword.strip()}' found in paragraph: {paragraph.get_text().strip()}")
                            except:
                                print("Error found when scraping")
                            try:
                                with open('webscrape.csv', 'w', newline='') as text_file:
                                    writer = csv.writer(text_file)
                                    for string in results:
                                        writer.writerow([string])
                            except:
                                print("Error writing to CSV file")
                                ## text_file.write(str(keyword.strip()))
                    
                </pyscript>
            </script> -->





</body>

</html>